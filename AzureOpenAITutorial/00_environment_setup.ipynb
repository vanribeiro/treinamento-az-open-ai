{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d37c89c9-77cb-4f32-ab78-1fee414c78e9",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    },
    "tags": []
   },
   "source": [
    "# Setup do Ambiente\n",
    "\n",
    "Este notebook serve para instalar as bibliotecas e garantir que o seu ambiente estÃ¡ operacional\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b4b2bbe6-8b5b-45cf-b4ad-29e32099a0de",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting openai\n",
      "  Using cached openai-0.27.6-py3-none-any.whl (71 kB)\n",
      "Requirement already satisfied: python-dotenv in c:\\python310\\lib\\site-packages (1.0.0)\n",
      "Collecting langchain\n",
      "  Using cached langchain-0.0.173-py3-none-any.whl (858 kB)\n",
      "Requirement already satisfied: plotly in c:\\python310\\lib\\site-packages (5.14.1)\n",
      "Collecting scikit-learn\n",
      "  Using cached scikit_learn-1.2.2-cp310-cp310-win_amd64.whl (8.3 MB)\n",
      "Collecting tiktoken\n",
      "  Using cached tiktoken-0.4.0-cp310-cp310-win_amd64.whl (635 kB)\n",
      "Requirement already satisfied: faiss-cpu in c:\\python310\\lib\\site-packages (1.7.4)\n",
      "Requirement already satisfied: tqdm in c:\\python310\\lib\\site-packages (from openai) (4.65.0)\n",
      "Collecting aiohttp\n",
      "  Using cached aiohttp-3.8.4-cp310-cp310-win_amd64.whl (319 kB)\n",
      "Collecting requests>=2.20\n",
      "  Using cached requests-2.30.0-py3-none-any.whl (62 kB)\n",
      "Requirement already satisfied: pydantic<2,>=1 in c:\\python310\\lib\\site-packages (from langchain) (1.10.7)\n",
      "Collecting SQLAlchemy<3,>=1.4\n",
      "  Using cached SQLAlchemy-2.0.14-cp310-cp310-win_amd64.whl (2.0 MB)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in c:\\python310\\lib\\site-packages (from langchain) (8.2.2)\n",
      "Collecting async-timeout<5.0.0,>=4.0.0\n",
      "  Using cached async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
      "Requirement already satisfied: PyYAML>=5.4.1 in c:\\python310\\lib\\site-packages (from langchain) (6.0)\n",
      "Requirement already satisfied: numpy<2,>=1 in c:\\python310\\lib\\site-packages (from langchain) (1.24.3)\n",
      "Collecting openapi-schema-pydantic<2.0,>=1.2\n",
      "  Using cached openapi_schema_pydantic-1.2.4-py3-none-any.whl (90 kB)\n",
      "Collecting numexpr<3.0.0,>=2.8.4\n",
      "  Using cached numexpr-2.8.4-cp310-cp310-win_amd64.whl (92 kB)\n",
      "Collecting dataclasses-json<0.6.0,>=0.5.7\n",
      "  Using cached dataclasses_json-0.5.7-py3-none-any.whl (25 kB)\n",
      "Requirement already satisfied: packaging in c:\\users\\v.cristiane.ribeiro\\appdata\\roaming\\python\\python310\\site-packages (from plotly) (23.1)\n",
      "Collecting scipy>=1.3.2\n",
      "  Using cached scipy-1.10.1-cp310-cp310-win_amd64.whl (42.5 MB)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\python310\\lib\\site-packages (from scikit-learn) (3.1.0)\n",
      "Collecting joblib>=1.1.1\n",
      "  Using cached joblib-1.2.0-py3-none-any.whl (297 kB)\n",
      "Requirement already satisfied: regex>=2022.1.18 in c:\\python310\\lib\\site-packages (from tiktoken) (2023.5.5)\n",
      "Collecting charset-normalizer<4.0,>=2.0\n",
      "  Using cached charset_normalizer-3.1.0-cp310-cp310-win_amd64.whl (97 kB)\n",
      "Collecting yarl<2.0,>=1.0\n",
      "  Using cached yarl-1.9.2-cp310-cp310-win_amd64.whl (61 kB)\n",
      "Collecting multidict<7.0,>=4.5\n",
      "  Using cached multidict-6.0.4-cp310-cp310-win_amd64.whl (28 kB)\n",
      "Collecting aiosignal>=1.1.2\n",
      "  Using cached aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "Collecting attrs>=17.3.0\n",
      "  Using cached attrs-23.1.0-py3-none-any.whl (61 kB)\n",
      "Collecting frozenlist>=1.1.1\n",
      "  Using cached frozenlist-1.3.3-cp310-cp310-win_amd64.whl (33 kB)\n",
      "Collecting marshmallow-enum<2.0.0,>=1.5.1\n",
      "  Using cached marshmallow_enum-1.5.1-py2.py3-none-any.whl (4.2 kB)\n",
      "Collecting typing-inspect>=0.4.0\n",
      "  Using cached typing_inspect-0.8.0-py3-none-any.whl (8.7 kB)\n",
      "Collecting marshmallow<4.0.0,>=3.3.0\n",
      "  Using cached marshmallow-3.19.0-py3-none-any.whl (49 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in c:\\python310\\lib\\site-packages (from pydantic<2,>=1->langchain) (4.5.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\python310\\lib\\site-packages (from requests>=2.20->openai) (2.0.2)\n",
      "Collecting idna<4,>=2.5\n",
      "  Using cached idna-3.4-py3-none-any.whl (61 kB)\n",
      "Collecting certifi>=2017.4.17\n",
      "  Using cached certifi-2023.5.7-py3-none-any.whl (156 kB)\n",
      "Collecting greenlet!=0.4.17\n",
      "  Using cached greenlet-2.0.2-cp310-cp310-win_amd64.whl (192 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\v.cristiane.ribeiro\\appdata\\roaming\\python\\python310\\site-packages (from tqdm->openai) (0.4.6)\n",
      "Collecting mypy-extensions>=0.3.0\n",
      "  Using cached mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
      "Installing collected packages: scipy, numexpr, mypy-extensions, multidict, marshmallow, joblib, idna, greenlet, frozenlist, charset-normalizer, certifi, attrs, async-timeout, yarl, typing-inspect, SQLAlchemy, scikit-learn, requests, openapi-schema-pydantic, marshmallow-enum, aiosignal, tiktoken, dataclasses-json, aiohttp, openai, langchain\n",
      "Successfully installed SQLAlchemy-2.0.14 aiohttp-3.8.4 aiosignal-1.3.1 async-timeout-4.0.2 attrs-23.1.0 certifi-2023.5.7 charset-normalizer-3.1.0 dataclasses-json-0.5.7 frozenlist-1.3.3 greenlet-2.0.2 idna-3.4 joblib-1.2.0 langchain-0.0.173 marshmallow-3.19.0 marshmallow-enum-1.5.1 multidict-6.0.4 mypy-extensions-1.0.0 numexpr-2.8.4 openai-0.27.6 openapi-schema-pydantic-1.2.4 requests-2.30.0 scikit-learn-1.2.2 scipy-1.10.1 tiktoken-0.4.0 typing-inspect-0.8.0 yarl-1.9.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 22.0.4; however, version 23.1.2 is available.\n",
      "You should consider upgrading via the 'c:\\Python310\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "pip install openai python-dotenv langchain plotly scikit-learn tiktoken faiss-cpu --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d9ee5317-298f-4c9d-bb98-c52459d6f160",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "openai.api_type = \"azure\"\n",
    "openai.api_version = \"2022-12-01\"\n",
    "\n",
    "API_KEY = os.getenv(\"OPENAI_API_KEY\",\"\").strip()\n",
    "assert API_KEY, \"ERROR: Azure OpenAI Key is missing\"\n",
    "openai.api_key = API_KEY\n",
    "\n",
    "RESOURCE_ENDPOINT = os.getenv(\"OPENAI_API_BASE\",\"\").strip()\n",
    "assert RESOURCE_ENDPOINT, \"ERROR: Azure OpenAI Endpoint is missing\"\n",
    "assert \"openai.azure.com\" in RESOURCE_ENDPOINT.lower(), \"ERROR: Azure OpenAI Endpoint should be in the form: \\n\\n\\t<your unique endpoint identifier>.openai.azure.com\"\n",
    "openai.api_base = RESOURCE_ENDPOINT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "67e8d27d-397f-4860-bcd2-85bcea88344a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<OpenAIObject text_completion id=cmpl-7HiDkaemYAFqUHdvdvcR69In4bhox at 0x1f020eda750> JSON: {\n",
       "  \"choices\": [\n",
       "    {\n",
       "      \"finish_reason\": \"stop\",\n",
       "      \"index\": 0,\n",
       "      \"logprobs\": null,\n",
       "      \"text\": \"\\n\\nI'm doing well, thank you for asking. How about you?\"\n",
       "    }\n",
       "  ],\n",
       "  \"created\": 1684455916,\n",
       "  \"id\": \"cmpl-7HiDkaemYAFqUHdvdvcR69In4bhox\",\n",
       "  \"model\": \"text-davinci-003\",\n",
       "  \"object\": \"text_completion\",\n",
       "  \"usage\": {\n",
       "    \"completion_tokens\": 16,\n",
       "    \"prompt_tokens\": 6,\n",
       "    \"total_tokens\": 22\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import openai\n",
    "# Simple API Call\n",
    "openai.Completion.create(\n",
    "    engine=\"text-davinci-003\",\n",
    "    prompt=\"Hello, how are you?\",\n",
    "    max_tokens=60\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a55eefe5-5122-4858-9978-b87b3a2be619",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
