{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "openai.api_type = \"azure\"\n",
    "openai.api_version = \"2022-12-01\"\n",
    "\n",
    "API_KEY = os.getenv(\"OPENAI_API_KEY\",\"OPENAI_API_BASE\").strip()\n",
    "assert API_KEY, \"ERROR: Azure OpenAI Key is missing\"\n",
    "openai.api_key = API_KEY\n",
    "\n",
    "RESOURCE_ENDPOINT = os.getenv(\"OPENAI_API_BASE\",\"\").strip()\n",
    "assert RESOURCE_ENDPOINT, \"ERROR: Azure OpenAI Endpoint is missing\"\n",
    "assert \"openai.azure.com\" in RESOURCE_ENDPOINT.lower(), \"ERROR: Azure OpenAI Endpoint should be in the form: \\n\\n\\t<your unique endpoint identifier>.openai.azure.com\"\n",
    "openai.api_base = RESOURCE_ENDPOINT"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# temperature\n",
    "\n",
    "Padrão é 1.\n",
    "\n",
    "Pode ser visto como a \"Criatividade\" do modelo. Um valor mais algo, significa que o modelo vai tomar mais risco. Usamos 0.9 para aplicações mais criativas e 0 para as que queremos uma resposta bem definida.\n",
    "\n",
    "Não é recomendado alterar temperature e top_p ao mesmo tempo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def call_openai(num_times, prompt, temperature):\n",
    "    for i in range(num_times):\n",
    "        \n",
    "        response = openai.Completion.create(\n",
    "            engine=os.getenv('DEPLOYMENT_NAME'),\n",
    "            prompt=prompt,\n",
    "            max_tokens=60,\n",
    "            temperature = temperature\n",
    "        )\n",
    "        print(response['choices'][0]['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "call_openai(3, 'The best pet is a ', temperature = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "call_openai(10, 'The best pet is a ', temperature = 1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# top_p\n",
    "\n",
    "Padrão é 1\n",
    "\n",
    "Uma alternativa à temperatuda. O Modelo irá considerar apenas os tokens com probabilidade igual a esse parametro. Então 0.1 significa que apenas as respostas com até 10% de probabilidae serão consideradas.\n",
    "\n",
    "Não é recomendado alterar temperature e top_p ao mesmo tempo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def call_openai(num_times, prompt, top_p):\n",
    "    for i in range(num_times):\n",
    "        \n",
    "        response = openai.Completion.create(\n",
    "            engine=os.getenv('DEPLOYMENT_NAME'),\n",
    "            prompt=prompt,\n",
    "            max_tokens=60,\n",
    "            top_p = top_p\n",
    "        )\n",
    "        print(response['choices'][0]['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "call_openai(3, 'The best pet is a ', top_p = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "call_openai(3, 'The best pet is a ', top_p = 0.1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# n\n",
    "\n",
    "Padrão é 1\n",
    "\n",
    "Quantas alternativas serão geradas para cada prompt.\n",
    "\n",
    "Nota: Cada alternativa irá consumir tokens separadamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "response = openai.Completion.create(\n",
    "            engine=os.getenv('DEPLOYMENT_NAME'),\n",
    "            prompt='The best pet is a ',\n",
    "            max_tokens=60,\n",
    "            n=2\n",
    "        )\n",
    "\n",
    "for c in response['choices']:\n",
    "    print(c['text'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# logprobs\n",
    "\n",
    "Padrão é null (não retornar)\n",
    "\n",
    "Retorna a probabilidade dos tokens. Por exemplo, se logprobs for 5, a API irár retornar a lista dos 5 tokens mais provaveis. \n",
    "\n",
    "O maior valor permitido para logprobs é 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "response = openai.Completion.create(\n",
    "            engine=os.getenv('DEPLOYMENT_NAME'),\n",
    "            prompt='The best pet is a ',\n",
    "            max_tokens=60,\n",
    "            logprobs = 2,\n",
    "        )\n",
    "\n",
    "print(response['choices'][0]['logprobs'])\n",
    "print(response['choices'][0]['text'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "2139c70ac98f3202d028164a545621647e07f47fd6f5d8ac55cf952bf7c15ed1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
